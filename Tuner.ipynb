{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(layer_1, layer_2, dense_units):\n",
    "#     model = Sequential(\n",
    "#         name='wake_word',\n",
    "#         layers=[\n",
    "#             Conv2D(\n",
    "#                 filters=layer_1[0],\n",
    "#                 kernel_size=layer_1[1],\n",
    "#                 activation='relu',\n",
    "#                 padding='same',\n",
    "#                 input_shape=INPUT_SHAPE,\n",
    "#                 name='conv2d_1'\n",
    "#             ),\n",
    "#             MaxPooling2D(\n",
    "#                 pool_size=layer_1[2],\n",
    "#                 padding='same',\n",
    "#                 name='pool2d_1'\n",
    "#             ),\n",
    "#             Dropout(\n",
    "#                 rate=0.1,\n",
    "#                 name='dropout_1'\n",
    "#             ),\n",
    "#             Conv2D(\n",
    "#                 filters=layer_2[0],\n",
    "#                 kernel_size=layer_2[1],\n",
    "#                 activation='relu',\n",
    "#                 padding='same',\n",
    "#                 name='conv2d_2'\n",
    "#             ),\n",
    "#             MaxPooling2D(\n",
    "#                 pool_size=layer_2[2],\n",
    "#                 padding='same',\n",
    "#                 name='pool2d_2'\n",
    "#             ),\n",
    "#             Dropout(\n",
    "#                 rate=0.1,\n",
    "#                 name='dropout_2'\n",
    "#             ),\n",
    "#             Flatten(),\n",
    "#             Dense(\n",
    "#                 units=dense_units,\n",
    "#                 activation='relu',\n",
    "#                 name='dense_1'\n",
    "#             ),\n",
    "#             Dropout(\n",
    "#                 rate=0.1,\n",
    "#                 name='dropout_3'\n",
    "#             ),\n",
    "#             Dense(\n",
    "#                 units=1,\n",
    "#                 activation='sigmoid',\n",
    "#                 name='output'\n",
    "#             )\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=Adam(learning_rate=1e-3),\n",
    "#         loss=BinaryCrossentropy(),\n",
    "#         metrics=[\n",
    "#             BinaryAccuracy(),\n",
    "#             Precision(),\n",
    "#             Recall(),\n",
    "#             FalsePositives(),\n",
    "#             FalseNegatives()\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if HYPERTUNING:\n",
    "#     tuner = kt.Hyperband(\n",
    "#         model_builder,\n",
    "#         objective='val_binary_accuracy',\n",
    "#         max_epochs=EPOCHS * 2,\n",
    "#         directory='tuner',\n",
    "#         project_name='wake_word',\n",
    "#         overwrite=True,\n",
    "#         max_model_size=MAX_MODEL_SIZE,\n",
    "#         max_consecutive_failed_trials=8\n",
    "#     )\n",
    "#     tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if HYPERTUNING:\n",
    "#     tuner.search(train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=[earlystop], verbose=2)\n",
    "#     tuner.results_summary()\n",
    "#     # first round -> 34 models\n",
    "#     # second round -> 17 + 6 new models (23 total)\n",
    "#     # third round -> 8 models ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if HYPERTUNING:\n",
    "#     model = tuner.get_best_models(num_models=1)[0]\n",
    "# else:\n",
    "#     model = build_model(*DEFAULT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential(\n",
    "#     name='wake_word',\n",
    "#     layers=[\n",
    "# #         LSTM(64, return_sequences=True, input_shape=(99, 86)),\n",
    "# #         Dropout(0.5),\n",
    "# #         LSTM(64),\n",
    "# #         Dropout(0.5),\n",
    "# #         Dense(1, activation='sigmoid')\n",
    "#         Conv2D(\n",
    "#             filters=32,\n",
    "#             kernel_size=5,\n",
    "#             activation='relu',\n",
    "#             padding='same',\n",
    "#             input_shape=INPUT_SHAPE,\n",
    "#             name='conv2d_1'\n",
    "#         ),\n",
    "#         MaxPooling2D(\n",
    "#             pool_size=4,\n",
    "#             padding='same',\n",
    "#             name='pool2d_1'\n",
    "#         ),\n",
    "#         Conv2D(\n",
    "#             filters=64,\n",
    "#             kernel_size=4,\n",
    "#             activation='relu',\n",
    "#             padding='same',\n",
    "#             name='conv2d_2'\n",
    "#         ),\n",
    "#         MaxPooling2D(\n",
    "#             pool_size=3,\n",
    "#             padding='same',\n",
    "#             name='pool2d_2'\n",
    "#         ),\n",
    "#         Conv2D(\n",
    "#             filters=64,\n",
    "#             kernel_size=3,\n",
    "#             activation='relu',\n",
    "#             padding='same',\n",
    "#             name='conv2d_3'\n",
    "#         ),\n",
    "#         MaxPooling2D(\n",
    "#             pool_size=2,\n",
    "#             padding='same',\n",
    "#             name='pool2d_3'\n",
    "#         ),\n",
    "#         Flatten(),\n",
    "#         Dense(\n",
    "#             units=64,\n",
    "#             activation='relu',\n",
    "#             name='dense_1'\n",
    "#         ),\n",
    "#         Dropout(\n",
    "#             rate=0.2,\n",
    "#             name='dropout_1'\n",
    "#         ),\n",
    "# #         Dense(\n",
    "# #             units=64,\n",
    "# #             activation='relu',\n",
    "# #             name='dense_2'\n",
    "# #         ),\n",
    "# #         Dropout(\n",
    "# #             rate=0.2,\n",
    "# #             name='dropout_2'\n",
    "# #         ),\n",
    "#         Dense(\n",
    "#             units=1,\n",
    "#             activation='sigmoid',\n",
    "#             name='output'\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=Adam(learning_rate=1e-3),\n",
    "#     loss=BinaryCrossentropy(),\n",
    "#     metrics=[\n",
    "#         BinaryAccuracy(),\n",
    "#         Precision(),\n",
    "#         Recall(),\n",
    "#         FalsePositives(),\n",
    "#         FalseNegatives()\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input(shape=[99, 43, 1])\n",
    "# reshaped = Reshape((99, 43))(inputs)\n",
    "\n",
    "# conv1D = Conv1D(8, 3, activation='relu', padding='same')(reshaped)\n",
    "# # conv1D = AveragePooling1D(2, padding='same')(conv1D)\n",
    "# conv1D = SeparableConv1D(8, 3, activation='relu', dilation_rate=2, padding='same')(conv1D)\n",
    "# conv1D = SeparableConv1D(8, 3, activation='relu', dilation_rate=4, padding='same')(conv1D)\n",
    "# conv1D = AveragePooling1D(5, padding='same')(conv1D)\n",
    "\n",
    "# conv1D = Flatten()(conv1D)\n",
    "# conv1D = Dense(16, activation='relu')(conv1D)\n",
    "# conv1D = Dropout(0.2)(conv1D)\n",
    "\n",
    "# # conv2D = Reshape((FRAMES, 13, 1))(reshaped)\n",
    "\n",
    "# conv2D = Conv2D(8, 3, activation='relu', padding='same')(inputs)\n",
    "# # conv2D = AveragePooling2D([2, 2], padding='same')(conv2D)\n",
    "# conv2D = SeparableConv2D(8, 3, activation='relu', dilation_rate=[2, 1], padding='same')(conv2D)\n",
    "# conv2D = SeparableConv2D(8, 3, activation='relu', dilation_rate=[4, 1], padding='same')(conv2D)\n",
    "# conv2D = AveragePooling2D([20, 10], padding='same')(conv2D)\n",
    "\n",
    "# conv2D = Flatten()(conv2D)\n",
    "# conv2D = Dense(16, activation='relu')(conv2D)\n",
    "# conv2D = Dropout(0.2)(conv2D)\n",
    "\n",
    "# combined = Concatenate()([conv1D, conv2D])\n",
    "# outputs = Dense(3, name='y_pred', activation='softmax')(combined)\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "\n",
    "# tf.keras.utils.plot_model(\n",
    "#     model,\n",
    "#     to_file='model.png',\n",
    "#     show_shapes=True,\n",
    "#     show_layer_activations=True,\n",
    "#     show_trainable=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in train_ds.take(BATCH_SIZE):\n",
    "#     print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=EPOCHS,\n",
    "#     callbacks=[earlystop]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.trainable = False\n",
    "# model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_optimal_threshold(m):\n",
    "#     scores = m.predict(test_ds)\n",
    "#     precision, recall, thresholds = precision_recall_curve(test_y, scores)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "#     plt.xlabel('Recall')\n",
    "#     plt.ylabel('Precision')\n",
    "#     plt.title('Precision-Recall trade-off')\n",
    "#     plt.legend(loc='lower left')\n",
    "#     plt.show()\n",
    "\n",
    "#     f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "#     optimal_idx = np.argmax(f1_scores)\n",
    "#     optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "#     return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THRESHOLD = get_optimal_threshold(model)\n",
    "# print(f'Optimal threshold for model is: {THRESHOLD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if QUANTIZATION:\n",
    "#     model.trainable = True\n",
    "#     q_aware_model = quantize_model(model)\n",
    "\n",
    "#     q_aware_model.compile(\n",
    "#         optimizer=Adam(),\n",
    "#         loss=BinaryCrossentropy(),\n",
    "#         metrics=[\n",
    "#             BinaryAccuracy(),\n",
    "#             Precision(),\n",
    "#             Recall(),\n",
    "#             FalsePositives(),\n",
    "#             FalseNegatives()\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     q_aware_model.summary()\n",
    "\n",
    "#     tf.keras.utils.plot_model(\n",
    "#         q_aware_model,\n",
    "#         to_file='q_aware_model.png',\n",
    "#         show_shapes=True,\n",
    "#         show_layer_activations=True,\n",
    "#         show_trainable=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if QUANTIZATION:\n",
    "#     q_history = q_aware_model.fit(\n",
    "#         train_ds,\n",
    "#         validation_data=val_ds,\n",
    "#         epochs=1\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if QUANTIZATION:\n",
    "#     q_aware_model.trainable = False\n",
    "#     q_aware_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if QUANTIZATION:\n",
    "#     THRESHOLD = get_optimal_threshold(q_aware_model)\n",
    "#     print(f'Optimal threshold for quantization aware model is: {THRESHOLD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if QUANTIZATION:\n",
    "#     model_to_convert = q_aware_model\n",
    "# else:\n",
    "#     model_to_convert = model\n",
    "\n",
    "# def representative_dataset_gen():\n",
    "#     for data in test_x:\n",
    "#         yield [np.expand_dims(data, 0)]\n",
    "\n",
    "# c = tflite.TFLiteConverter.from_keras_model(model_to_convert)\n",
    "# c.target_spec.supported_ops = [tflite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# c.optimizations = [tflite.Optimize.DEFAULT]\n",
    "# c.representative_dataset = representative_dataset_gen\n",
    "# tflite_model = c.convert()\n",
    "\n",
    "# open('model.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tflite.experimental.Analyzer.analyze(model_content=tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_x = np.concatenate((train_x, val_x, test_x))\n",
    "# all_data_y = np.concatenate((train_y, val_y, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpreter = tflite.Interpreter(model_path=str('model.tflite'))\n",
    "# interpreter.allocate_tensors()\n",
    "# # print(interpreter)\n",
    "\n",
    "# input_details = interpreter.get_input_details()[0]\n",
    "# output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "# score = 0\n",
    "# no_samples = len(all_data_x)\n",
    "# # indexes = np.random.randint(0, 40000, size=no_samples)\n",
    "# progress_bar = tqdm(total=no_samples, desc='Testing samples')\n",
    "\n",
    "# for i in range(len(all_data_x)): # data, label in all_data_x, all_data_y: #test_ds.take(BATCH_SIZE // 2):\n",
    "# #     for i in range(data.shape[0]):\n",
    "#     d = tf.expand_dims(all_data_x[i], 0)\n",
    "#     l = all_data_y[i]\n",
    "\n",
    "#     interpreter.set_tensor(input_details['index'], d)\n",
    "#     interpreter.invoke()\n",
    "#     output = np.argmax(interpreter.get_tensor(output_details['index'])[0])\n",
    "\n",
    "# #         wake_word_detected = 1 if output > 0.5 else 0.0\n",
    "#     if l == output:\n",
    "#         score += 1\n",
    "#     else:\n",
    "#         print(l, output)\n",
    "\n",
    "#     progress_bar.update()\n",
    "\n",
    "# print(score / no_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_builder(hp):\n",
    "#     conv_filters_1 = hp.Int(\n",
    "#         name='conv_filters_1',\n",
    "#         min_value=16,\n",
    "#         max_value=64,\n",
    "#         step=2,\n",
    "#         sampling='log'\n",
    "#     )\n",
    "#     conv_kernel_1 = hp.Choice(\n",
    "#         name='conv_kernel_1',\n",
    "#         values=[3, 4, 5]\n",
    "#     )\n",
    "#     pooling_1 = hp.Choice(\n",
    "#         name='pooling_1',\n",
    "#         values=[3, 4, 5]\n",
    "#     )\n",
    "#     conv_filters_2 = hp.Int(\n",
    "#         name='conv_filters_2',\n",
    "#         min_value=16,\n",
    "#         max_value=64,\n",
    "#         step=2,\n",
    "#         sampling='log'\n",
    "#     )\n",
    "#     conv_kernel_2 = hp.Choice(\n",
    "#         name='conv_kernel_2',\n",
    "#         values=[3, 4, 5]\n",
    "#     )\n",
    "#     pooling_2 = hp.Choice(\n",
    "#         name='pooling_2',\n",
    "#         values=[3, 4, 5]\n",
    "#     )\n",
    "#     dense_units = hp.Int(\n",
    "#         name='dense_units',\n",
    "#         min_value=16,\n",
    "#         max_value=128,\n",
    "#         step=2,\n",
    "#         sampling='log'\n",
    "#     )\n",
    "\n",
    "#     return build_model(\n",
    "#         [conv_filters_1, conv_kernel_1, pooling_1],\n",
    "#         [conv_filters_2, conv_kernel_2, pooling_2],\n",
    "#         dense_units\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
